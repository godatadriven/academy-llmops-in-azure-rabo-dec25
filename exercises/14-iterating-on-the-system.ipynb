{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating on the system ðŸ”„\n",
    "\n",
    "With the most important components in place for evaluating, experimenting with, and monitoring the system, we can now iterate on the system to improve it.\n",
    "\n",
    "This will be more of a free format, where the choice is up to you what you wish to iterate on. Here are some suggestions:\n",
    "\n",
    "- **Improving latency** \n",
    "  - Look into asynchronous processing\n",
    "  - Combine multiple requests\n",
    "  - Try different models for different tasks\n",
    "- **Improve evaluation metrics**\n",
    "  - Try different models and parameters\n",
    "  - Add metrics and extend evaluation\n",
    "  - Use [advanced prompting techniques](https://python.useinstructor.com/prompting/)\n",
    "- **Address downvoted outputs**\n",
    "  - Label downvoted article outputs, and add to evaluation data\n",
    "  - Improve model to address downvoted outputs\n",
    "- **Improve monitoring results**\n",
    "  - Reduce number of tokens, increase success rates, ...\n",
    "  - Extend dashboad with useful widgets\n",
    "- **Other**\n",
    "  - Extend unit tests\n",
    "  - Ensure extracted quotes are actually in the article (see [inspiration](https://python.useinstructor.com/examples/exact_citations/))\n",
    "  - Run the evaluations in a Azure ML job so we can run them on a schedule\n",
    "  - ... And many more!\n",
    "\n",
    "Most importantly, try to make your progress visible/measurable.\n",
    "We have experiments, logs, traces, a monitoring dashboard that we can use,\n",
    "so try to iterate in a way that is visible in these tools.\n",
    "\n",
    "If you wish to improve something that is not yet measurable or visualized in our monitoring setup, try to extend the monitoring setup first to include it! For example, we are currently not logging which model we are using, but that could be a useful addition to the logs if we are experimenting with different models.\n",
    "\n",
    "So at each step: check logs/traces/metrics, improve, re-deploy, collect monitoring data, repeat.\n",
    "\n",
    "Good luck! ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for more inspiration, here are some deepdive examples of our feedback data! ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from llmops_training.news_reader.logs import load_entries_with_feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downvoted = load_entries_with_feedback(\"downvote\", from_hours_ago=1.5)\n",
    "upvoted = load_entries_with_feedback(\"upvote\", from_hours_ago=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 2.5))\n",
    "\n",
    "downvotes = [len(downvoted), 0]\n",
    "upvotes = [0, len(upvoted)]\n",
    "\n",
    "plt.bar([\"downvotes\", \"upvotes\"], downvotes, color=\"red\", alpha=0.7, label=\"downvotes\")\n",
    "plt.bar([\"downvotes\", \"upvotes\"], upvotes, color=\"green\", alpha=0.7, label=\"upvotes\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.ylabel(\"# votes\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downvoted_events = [entry[\"jsonPayload\"][\"event\"] for entry in downvoted]\n",
    "upvoted_events = [entry[\"jsonPayload\"][\"event\"] for entry in upvoted]\n",
    "\n",
    "all_events = list(set(downvoted_events + upvoted_events))\n",
    "\n",
    "downvote_counts = [downvoted_events.count(event) for event in all_events]\n",
    "upvote_counts = [upvoted_events.count(event) for event in all_events]\n",
    "\n",
    "x = np.arange(len(all_events))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 2.5))\n",
    "\n",
    "rects1 = ax.bar(x - width/2, downvote_counts, width, label='Downvotes', color='red', alpha=0.7)\n",
    "rects2 = ax.bar(x + width/2, upvote_counts, width, label='Upvotes', color='green', alpha=0.7)\n",
    "\n",
    "ax.set_ylabel('# votes')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(all_events)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downvoted_lengths = [len(entry[\"jsonPayload\"][\"article\"]) for entry in downvoted]\n",
    "upvoted_lengths = [len(entry[\"jsonPayload\"][\"article\"]) for entry in upvoted]\n",
    "\n",
    "downvoted_mean = np.mean(downvoted_lengths)\n",
    "downvoted_std = np.std(downvoted_lengths)\n",
    "upvoted_mean = np.mean(upvoted_lengths)\n",
    "upvoted_std = np.std(upvoted_lengths)\n",
    "\n",
    "categories = ['Downvoted', 'Upvoted']\n",
    "means = [downvoted_mean, upvoted_mean]\n",
    "stds = [downvoted_std, upvoted_std]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 2.5))\n",
    "\n",
    "for i, (mean, std, c) in enumerate(zip(means, stds, [(0.7,0,0,0.7), (0,0.7,0,0.7)]), 1):\n",
    "    ax.errorbar(mean, i, xerr=std, fmt='o', capsize=5, color=c, markersize=10)\n",
    "\n",
    "ax.set_xlabel('Average article length')\n",
    "ax.set_title('Average article length with standard deviation')\n",
    "ax.set_yticks(range(0, 4))\n",
    "ax.set_yticklabels([\"\"] + categories + [\"\"])\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_downvoted = [entry for entry in downvoted if \"title\" in entry[\"jsonPayload\"][\"output\"]]\n",
    "_upvoted = [entry for entry in upvoted if \"title\" in entry[\"jsonPayload\"][\"output\"]]\n",
    "\n",
    "downvoted_lengths = [len(entry[\"jsonPayload\"][\"output\"][\"title\"]) for entry in _downvoted]\n",
    "upvoted_lengths = [len(entry[\"jsonPayload\"][\"output\"][\"title\"]) for entry in _upvoted]\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "downvoted_mean = np.mean(downvoted_lengths)\n",
    "downvoted_std = np.std(downvoted_lengths)\n",
    "upvoted_mean = np.mean(upvoted_lengths)\n",
    "upvoted_std = np.std(upvoted_lengths)\n",
    "\n",
    "categories = ['Downvoted', 'Upvoted']\n",
    "means = [downvoted_mean, upvoted_mean]\n",
    "stds = [downvoted_std, upvoted_std]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 2.5))\n",
    "\n",
    "for i, (mean, std, c) in enumerate(zip(means, stds, [(0.7,0,0,0.7), (0,0.7,0,0.7)]), 1):\n",
    "    ax.errorbar(mean, i, xerr=std, fmt='o', capsize=5, color=c, markersize=10)\n",
    "\n",
    "ax.set_xlabel('Average output title length')\n",
    "ax.set_title('Average output title length with standard deviation')\n",
    "ax.set_yticks(range(0, 4))\n",
    "ax.set_yticklabels([\"\"] + categories + [\"\"])\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
