{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect user feedback ðŸ‘\n",
    "\n",
    "One final addition to the app is to collect user feedback.\n",
    "\n",
    "This provides an invaluable source of information for improving the app and understanding how users are interacting with it.\n",
    "\n",
    "In this notebook, we will add user feedback buttons to the app, connect feedback to corresponding traces, and explore the feedback data from the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For autoreloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending app with feedback buttons\n",
    "\n",
    "We will add feedback buttons for each of the outputs in the app, so for the `title`, `summary`, etc.\n",
    "\n",
    "Having as specific feedback as possible the better, but we also want to keep the feedback process simple and quick.\n",
    "\n",
    "> **Exercise** ðŸ“\n",
    ">\n",
    "> - Explore the provided function `write_and_collect_feedback` in the `app/utils.py` file.\n",
    "> - Fill in the TODO's `# TODO(13-collect-feedback)` in `components.py` to collect feedback for each model output.\n",
    "> - Rerun the app locally to check if the buttons were added correctly\n",
    "> \n",
    "\n",
    "The buttons might not work yet, because they're trying to store the feedback associated with the corresponding `trace_id` in the cloud, but we haven't passed the correct `trace_id` along with the feedback yet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging feedback with trace\n",
    "\n",
    "Now, it's important that the feedback is associated to the correct trace.\n",
    "\n",
    "> **Exercise** ðŸ“\n",
    ">\n",
    "> - Fill in the TODO's `# TODO(13-feedback-with-trace)` in both `components.py` and `extraction.py` to make sure that feedback is associated with the correct traces.\n",
    "> - Run the app again, and trigger the feedback buttons so that the feedback is logged in the cloud.\n",
    "> - Check the Azure Monitor, to see if the logs are being stored correctly.\n",
    ">\n",
    "> ðŸ’¡ Hint:\n",
    ">\n",
    "> - Where it might now say `results, _ = extract_info_from_articles(articles)` in `components.py`, you might want to change it to `results, trace_ids = ...` and then store the trace IDs in the streamlit session state, `st.session_state[\"trace_ids\"] = trace_ids`, so they can be used for logging the feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading feedback data from cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have traces, logs, feedback, on which we can create new metrics and insights in our monitoring dashboard.\n",
    "We can query downvoted feedback in the Logs Explorer, to collect traces to subsequently inspect in the Trace Explorer.\n",
    "We can do a lot now!\n",
    "\n",
    "But not only can we interact with our data in the cloud, we can also load it in and analyse it programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmops_training.news_reader.logs import load_entries_with_feedback, load_feedback_entries \n",
    "from llmops_training.news_reader.extraction import extract_general_info\n",
    "from llmops_training.news_reader.logs import configure_structlog, configure_tracer\n",
    "\n",
    "configure_structlog()\n",
    "configure_tracer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downvote_entries = load_feedback_entries(\"downvote\", from_hours_ago=1)\n",
    "upvote_entries = load_feedback_entries(\"upvote\", from_hours_ago=1)\n",
    "\n",
    "if downvote_entries:\n",
    "    print(downvote_entries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: if this function fails, check the docstring to see how you can solve it.\n",
    "\n",
    "downvoted_entries = load_entries_with_feedback(\"downvote\", from_hours_ago=1)\n",
    "upvoted_entries = load_entries_with_feedback(\"upvote\", from_hours_ago=1)\n",
    "\n",
    "if downvoted_entries:\n",
    "    print(downvoted_entries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = extract_general_info(\n",
    "    prompt_template=\"\"\"\n",
    "    Extract structured information from the following article.\n",
    "    Give the title and a single sentence summary.\n",
    "    \n",
    "    Article: \\n{article}\n",
    "    \"\"\",\n",
    "    article=downvoted_entries[0][\"jsonPayload\"][\"article\"],\n",
    ")\n",
    "\n",
    "output.title"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
