{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling the LLM ðŸ§‘â€ðŸ’»\n",
    "\n",
    "In this notebook, we'll get familiar with calling the LLM API from code.\n",
    "\n",
    "In addition, we'll extend upon regular prompting by exploring how we can make the LLM generate structured outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, it's important to understand our package structure. As a warm up exercise, follow the instructions below to get familiar with the package structure.\n",
    "\n",
    "> **Exercise** ðŸ“\n",
    ">\n",
    "> - Inspect the `pyproject.toml`. This defines the project dependencies and configuration.\n",
    "> - Inspect the `src` folder. This is where the source code, or our package, lives.\n",
    "> - Navigate to the `generation` module in our package. What functions does it define?\n",
    "\n",
    "As you see, even though all exercises are in notebooks (for storytelling and visualization purposes), all of our important code lives in our package. \n",
    "\n",
    "We will use and extend our package throughout this training. Structuring your code like this is important to allow for better reusability, testability and maintainability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular prompting\n",
    "\n",
    "> **Exercise** ðŸ“\n",
    ">\n",
    "> - Before we call the LLM from code, take a minute to get familiar with the [Azure OpenAI playground in the portal](https://portal.azure.com/#view/Microsoft_Azure_ProjectOxford/CognitiveServicesHub/~/OpenAI) if you haven't already.\n",
    "> - Check out the [API reference](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference) to see how we can call the LLM from code.\n",
    "> - Now, fill in the TODO's in the `generation.py` module in `./src/llmops_training`, so we can call the LLM from code!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T10:35:06.861207Z",
     "start_time": "2025-12-15T10:35:06.469623Z"
    }
   },
   "source": [
    "from llmops_training.news_reader.generation import generate_text"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T10:35:09.810586Z",
     "start_time": "2025-12-15T10:35:07.442136Z"
    }
   },
   "source": [
    "prompt = \"Hi!\"\n",
    "generate_text(prompt)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi there! How can I help you today?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting structured information (naive)\n",
    "\n",
    "A common use case is to extract structured information from text. \n",
    "\n",
    "For example, given the text \"XYZ's stock price is expected to increase\", we might want to extract:\n",
    "- business: \"XYZ\"\n",
    "- stock price change: \"increase\"\n",
    "\n",
    "and store it in a data base.\n",
    "\n",
    "One way to do so, is to *ask* the LLM to generate the structured information for us in JSON format.\n",
    "\n",
    "> **Exercise** ðŸ“\n",
    ">\n",
    "> - Fill in the TODO below to try to extract structured information form the given sentence.\n",
    "> - Check if the output is in correct JSON format"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T10:35:40.355791Z",
     "start_time": "2025-12-15T10:35:40.337763Z"
    }
   },
   "source": [
    "from llmops_training.news_reader.utils import check_json"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T10:36:37.122203Z",
     "start_time": "2025-12-15T10:36:34.324212Z"
    }
   },
   "source": [
    "sentence = \"XYZ's stock price is expected to increase\"\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Extract the following fields in JSON format:\n",
    "   - \"business\": \"The business involved in the text (str)\",\n",
    "   - \"stock_price_change\": \"Whether stock price will 'increase' or 'decrease' (str)\"\n",
    "From the following sentence:\n",
    "{sentence}\n",
    "\"\"\"\n",
    "\n",
    "prompt = prompt_template.format(sentence=sentence)\n",
    "output = generate_text(prompt)\n",
    "print(output)\n",
    "\n",
    "#output = \"Not implemented yet!\" # TODO: Fill me in! Call the LLM"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"business\": \"XYZ\",\n",
      "  \"stock_price_change\": \"increase\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../solutions/calling-the-llm/generate-text.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if that worked."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T10:41:31.117339Z",
     "start_time": "2025-12-15T10:41:31.069473Z"
    }
   },
   "source": [
    "check_json(output)\n",
    "print(output)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid JSON! ðŸŽ‰\n",
      "{\n",
      "  \"business\": \"XYZ\",\n",
      "  \"stock_price_change\": \"increase\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ does that return \"_Not a valid JSON!_\"? That's okay! We expected that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, the LLM is free to format the output however it wants. It's not guaranteed to output a correct JSON structure. \n",
    "\n",
    "It gets close though, and with a few iterations we can probably get what we want, but there's a better way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting structured information (instructor)\n",
    "\n",
    "One way to guarantee the output is in the correct format, is to use [function calling](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/function-calling).\n",
    "\n",
    "Here, we pass a structured definition of the desired outputs to the LLM, and it will return a structured object.\n",
    "\n",
    "Now, there is a tool, called [Instructor](https://python.useinstructor.com/) that builds on this capability, and allows you to define a Pydantic schema for the LLM to generate. Let's see how that works."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T10:42:15.842672Z",
     "start_time": "2025-12-15T10:42:15.829287Z"
    }
   },
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "from llmops_training.news_reader.generation import generate_object"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the schema:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T10:42:29.832484Z",
     "start_time": "2025-12-15T10:42:29.795968Z"
    }
   },
   "source": [
    "class StructuredInfo(BaseModel):\n",
    "    business: str = Field(..., description=\"Business involved in the text\")\n",
    "    stock_price_change: Literal[\"increase\", \"decrease\"] = Field(..., description=\"Likely stock price change\")\n",
    "    \n",
    "prompt_template = \"Extract structured info from the sentence: {sentence}\"\n",
    "\n",
    "prompt = prompt_template.format(sentence=sentence)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T10:42:33.477808Z",
     "start_time": "2025-12-15T10:42:31.733545Z"
    }
   },
   "source": [
    "output = generate_object(prompt, StructuredInfo)\n",
    "output"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredInfo(business='XYZ', stock_price_change='increase')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `instructor` it's guaranteed in the right format!\n",
    "\n",
    "Now let's put this to use in our use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "academy-llmops-in-azure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
