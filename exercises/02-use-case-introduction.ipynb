{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use case introduction ðŸ“°\n",
    "\n",
    "In this notebook, we'll explore the use case of extracting structured information from news articles.\n",
    "\n",
    "In short, given a news article, the goal is to extract the following information:\n",
    "- The title of the article\n",
    "- A summary of the article\n",
    "- Whether the article is about business\n",
    "- For each mentioned business\n",
    "  - The name of the business\n",
    "  - The likely stock price change (increase, decrease, none)\n",
    "  - Reason for the stock price change\n",
    "  - Relevant substring supporting the reason\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using a dataset of BBC news articles for a specific month (see `get_bbc_news_sample` function below). The dataset contains the following columns: \n",
    "- `article`: The article as we would see it on the website.\n",
    "- `title`: The title of the article.\n",
    "- `is_business`: Whether the article is about business.\n",
    "- `description`: A short summary of the article.\n",
    "\n",
    "As you see, we start with a *labeled* data set, as is important for many use cases. If this is not available in your case, it may be worth to label a few samples to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmops_training.news_reader.data import get_bbc_news_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_bbc_news_sample()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the first article which is about business:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = data[data[\"is_business\"]].iloc[0].article\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the LLM output\n",
    "\n",
    "Now, let's define the Pydantic schema for the LLM to extract from each article.\n",
    "\n",
    "> **Exercise** ðŸ“\n",
    ">\n",
    "> - Fill in the TODO's below in the `ArticleInfo` Pydantic model.\n",
    "> - Subsequently, fill in the prompt in the next section to extract the information from an article.\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BusinessSpecificInfo(BaseModel):\n",
    "    business: str = Field(..., description=\"The business or company involved\")\n",
    "    stock_price_change: Literal[\"increase\", \"decrease\", \"none\"] = Field(\n",
    "        ..., description=\"\"\"\n",
    "        Possible stock price change as result of the article. \n",
    "        - \"increase\" if article speaks positively about the business\n",
    "        - \"decrease\" if article speaks negatively about the business\n",
    "        - \"none\" if article speaks neutrally about the business\n",
    "        \"\"\"\n",
    "    )\n",
    "    reason: str = Field(..., description=\"A single sentence reason for the possible stock price change\")\n",
    "    relevant_substring: str = Field(\n",
    "        ..., description=\"A relevant substring from the article supporting the reason (10-20 words)\"\n",
    "    )\n",
    "\n",
    "class ArticleInfo(BaseModel):\n",
    "    title: str = Field(..., description=\"The title of the article\")\n",
    "    summary: str = Field(..., description=\"A single sentence summary of the article\")\n",
    "    is_about_business: ...  # TODO: Fill me in! This should be a boolean (use Field here)\n",
    "    business_info: ...  # TODO: Fill me in! This should be a List of BusinessSpecificInfo objects (no need to use Field here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../solutions/use-case-introduction/pydantic-model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmops_training.news_reader.generation import generate_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"Extract structured information from the following article:\\n\\n{article}\"\n",
    "\n",
    "prompt = ...  # TODO: Fill me in! Use the .format function on prompt_template with an article of your choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../solutions/use-case-introduction/make-prompt.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if that worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = generate_object(prompt, ArticleInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra: check `generate_object` and figure out how to try different models! Try some different ones and see which one works well for this task.\n",
    "\n",
    "> Tip: Use `model_name` and try for example `gpt-5`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Bonus) Deep dive Instructor\n",
    "\n",
    "> **Exercise** ðŸ“\n",
    ">\n",
    "> - Step into the underlying code from `generate_object` and try to understand how Instructor extracts structured information from the text given a Pydantic base model.\n",
    "> - Does it use [Function Calling](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/function-calling)? Does it do retry iterations? Could we implement this ourselves? Discuss with your peers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "academy-llmops-in-azure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
